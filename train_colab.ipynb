{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QELM Training on Google Colab\n",
    "\n",
    "This notebook trains the embedding-based QELM system on GPU.\n",
    "\n",
    "**What it does:**\n",
    "1. Clones the code from GitHub\n",
    "2. Installs dependencies\n",
    "3. Mounts Google Drive for checkpoints\n",
    "4. Trains Stage 1 (supervised pretraining)\n",
    "5. Trains the two-tower recommender\n",
    "6. Tests the full system\n",
    "\n",
    "**Prerequisites:**\n",
    "- Push your code to GitHub\n",
    "- Set OpenAI API key (for question generation)\n",
    "- Use GPU runtime (Runtime → Change runtime type → GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Clone Code\n\n**For private repos**, you have 3 options:\n1. Make the repo public temporarily\n2. Use a Personal Access Token (see cell below for instructions)\n3. Upload code to Google Drive and copy from there\n\n**For public repos**, just run the clone command directly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository\n# Option 1: Public repo (easiest)\n!git clone https://github.com/makarovaalexa-brch/qelm-crs.git\n\n# Option 2: Private repo with personal access token\n# Create token at: https://github.com/settings/tokens (select 'repo' scope)\n# Then use: !git clone https://YOUR_TOKEN@github.com/makarovaalexa-brch/qelm-crs.git\n\n# Option 3: Upload files from Google Drive instead\n# Uncomment if you've already uploaded the code to Drive:\n# !cp -r /content/drive/MyDrive/qelm-crs /content/\n\n# Change to directory\n%cd qelm-crs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q openai\n",
    "!pip install -q pandas numpy scikit-learn tqdm\n",
    "!pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "!mkdir -p /content/drive/MyDrive/qelm_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Enter your OpenAI API key when prompted\n",
    "api_key = getpass('Enter OpenAI API Key: ')\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Download MovieLens 25M dataset\n!wget -nc https://files.grouplens.org/datasets/movielens/ml-25m.zip\n!unzip -n ml-25m.zip -d data/\n\n# Filter dataset\nimport pandas as pd\n\n# Load full dataset\nratings = pd.read_csv('data/ml-25m/ratings.csv')\nmovies = pd.read_csv('data/ml-25m/movies.csv')\n\nprint(f\"Original: {len(ratings)} ratings, {len(movies)} movies, {ratings['userId'].nunique()} users\")\n\n# Filter: Top 1000 most-rated movies\nmovie_counts = ratings['movieId'].value_counts()\ntop_movies = movie_counts.head(1000).index\nmovies_filtered = movies[movies['movieId'].isin(top_movies)]\n\n# Filter: Users with 50+ ratings on these top movies\nratings_filtered = ratings[ratings['movieId'].isin(top_movies)]\nuser_counts = ratings_filtered['userId'].value_counts()\nactive_users = user_counts[user_counts >= 50].index\nratings_filtered = ratings_filtered[ratings_filtered['userId'].isin(active_users)]\n\nprint(f\"Filtered: {len(ratings_filtered)} ratings, {len(movies_filtered)} movies, {len(active_users)} users\")\n\n# Save filtered data\nmovies_filtered.to_csv('data/ml-25m/movies_filtered.csv', index=False)\nratings_filtered.to_csv('data/ml-25m/ratings_filtered.csv', index=False)\n\nprint(f\"\\n✓ Saved filtered dataset to data/ml-25m/\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Download MovieLens Dataset\n\nWe'll use a filtered subset for faster training:\n- Top 1000 most-rated movies\n- Users with 50+ ratings (active users)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create sample Reddit data (or scrape real data)\n%cd /content/qelm-crs\n\n# Option 1: Use 5 sample posts (fast, for testing pipeline)\n!python src/qelm/data/reddit_scraper.py --sample --output-dir data/reddit\n\n# Option 2: Scrape real Reddit data (100 posts per subreddit, ~500 total)\n# Uncomment for actual training:\n# !python src/qelm/data/reddit_scraper.py --max-posts 100 --output-dir data/reddit"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify data\nimport json\n\nwith open('data/reddit/sample_conversations.json', 'r') as f:\n    data = json.load(f)\n    \nprint(f\"Loaded {len(data)} sample conversation pairs\")\nprint(\"\\nExample:\")\nprint(json.dumps(data[0], indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Train Stage 1 (Supervised Pretraining)\n\nThis teaches the RL actor to predict embeddings for **what to ask next**.\n\n**Key insight:** \n- Input: User's preference (\"I love Inception\")\n- Target: Concepts from helpful response (\"Have you seen Interstellar?\")\n- Model learns: User preference → Related concepts to explore\n\nThis is NOT just echoing the user - it's learning to ask exploratory follow-up questions!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import sys\n",
    "sys.path.append('/content/qelm-crs/src')\n",
    "\n",
    "from qelm.models.embedding_qelm import SentenceBERTEmbeddingSpace, EmbeddingActorCritic\n",
    "from qelm.training.stage1_supervised import Stage1Trainer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "print(\"Initializing SentenceBERT embedding space...\")\n",
    "embedding_space = SentenceBERTEmbeddingSpace(movielens_data_path=None)\n",
    "\n",
    "print(\"\\nInitializing RL actor...\")\n",
    "rl_agent = EmbeddingActorCritic(\n",
    "    state_dim=384,  # SentenceBERT\n",
    "    embedding_dim=384  # SentenceBERT\n",
    ")\n",
    "\n",
    "print(\"\\nInitializing encoder...\")\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"\\n✓ Initialization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create trainer\ntrainer = Stage1Trainer(\n    rl_agent=rl_agent,\n    embedding_space=embedding_space,\n    reddit_data_path='data/reddit',\n    encoder=encoder\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Stage 1\n",
    "trainer.train(\n",
    "    epochs=20,  # More epochs on GPU\n",
    "    batch_size=64,  # Larger batch on GPU\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Stage 1\n",
    "trainer.evaluate(num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint to Google Drive\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path('/content/drive/MyDrive/qelm_checkpoints')\n",
    "checkpoint_path = checkpoint_dir / 'stage1_final.pt'\n",
    "\n",
    "torch.save({\n",
    "    'actor_state_dict': rl_agent.actor.state_dict(),\n",
    "    'train_losses': trainer.train_losses,\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"✓ Saved checkpoint to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Initialize recommender with REAL MovieLens data\nmovie_catalog = MovieCatalog(movielens_data_path='data/ml-25m')\n\nrecommender = TwoTowerRecommender(\n    state_dim=384,\n    embedding_dim=128\n)\n\nrec_trainer = RecommenderTrainer(recommender, movie_catalog, encoder)\n\nprint(f\"✓ Loaded {len(movie_catalog.movies)} movies\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create training data from MovieLens ratings\n# For each user, create a \"conversation\" describing their preferences\n\ndef create_user_conversations(ratings_df, movies_df, num_users=100):\n    \"\"\"\n    Convert user ratings into conversation-like descriptions.\n    \n    For each user:\n    - Sample their top-rated movies\n    - Create a text description of their preferences\n    - Return (conversation_text, liked_movie_ids)\n    \"\"\"\n    conversations = []\n    liked_movies = []\n    \n    # Sample users\n    sampled_users = ratings_df['userId'].unique()[:num_users]\n    \n    for user_id in sampled_users:\n        user_ratings = ratings_df[ratings_df['userId'] == user_id]\n        \n        # Get movies they rated highly (>= 4.0)\n        high_ratings = user_ratings[user_ratings['rating'] >= 4.0]\n        \n        if len(high_ratings) < 3:\n            continue\n        \n        # Sample 3-5 movies they liked\n        sample_size = min(5, len(high_ratings))\n        sampled = high_ratings.sample(sample_size)\n        \n        # Get movie titles\n        movie_ids = sampled['movieId'].tolist()\n        movie_titles = []\n        for mid in movie_ids[:3]:  # Use first 3 for description\n            movie_row = movies_df[movies_df['movieId'] == mid]\n            if len(movie_row) > 0:\n                title = movie_row.iloc[0]['title']\n                movie_titles.append(title.split('(')[0].strip())\n        \n        # Create conversation text\n        if len(movie_titles) >= 2:\n            conversation = f\"I really enjoyed {movie_titles[0]} and {movie_titles[1]}\"\n            if len(movie_titles) > 2:\n                conversation += f\", as well as {movie_titles[2]}\"\n            \n            conversations.append(conversation)\n            liked_movies.append(movie_ids)\n    \n    return conversations, liked_movies\n\n# Load filtered ratings\nratings_df = pd.read_csv('data/ml-25m/ratings_filtered.csv')\nmovies_df = pd.read_csv('data/ml-25m/movies_filtered.csv')\n\n# Generate training data\nsample_conversations, sample_liked_movies = create_user_conversations(\n    ratings_df, \n    movies_df, \n    num_users=200  # Use 200 users for training\n)\n\nprint(f\"Created {len(sample_conversations)} training examples from real user data\")\nprint(f\"\\nExample conversation:\")\nprint(f\"  Text: {sample_conversations[0]}\")\nprint(f\"  Liked movies: {sample_liked_movies[0][:5]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize recommender\n",
    "movie_catalog = MovieCatalog(movielens_data_path=None)  # Use sample data\n",
    "\n",
    "recommender = TwoTowerRecommender(\n",
    "    state_dim=384,\n",
    "    embedding_dim=128\n",
    ")\n",
    "\n",
    "rec_trainer = RecommenderTrainer(recommender, movie_catalog, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data\n",
    "sample_conversations = [\n",
    "    \"I love action movies with great cinematography like The Dark Knight\",\n",
    "    \"I enjoy mind-bending sci-fi films like Inception and Interstellar\",\n",
    "    \"I prefer dark crime dramas with great dialogue like Pulp Fiction\",\n",
    "    \"I like sci-fi movies with philosophical themes like The Matrix\",\n",
    "    \"I want intense space exploration films like Interstellar\",\n",
    "] * 10  # Repeat for more training data\n",
    "\n",
    "sample_liked_movies = [\n",
    "    [1],  # The Dark Knight\n",
    "    [2, 5],  # Inception, Interstellar\n",
    "    [3],  # Pulp Fiction\n",
    "    [4],  # The Matrix\n",
    "    [5],  # Interstellar\n",
    "] * 10\n",
    "\n",
    "print(f\"Training on {len(sample_conversations)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train recommender\n",
    "rec_trainer.train(\n",
    "    conversations=sample_conversations,\n",
    "    liked_movies=sample_liked_movies,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save recommender checkpoint\n",
    "rec_checkpoint_path = checkpoint_dir / 'recommender_final.pt'\n",
    "\n",
    "torch.save({\n",
    "    'user_tower': recommender.user_tower.state_dict(),\n",
    "    'item_tower': recommender.item_tower.state_dict(),\n",
    "}, rec_checkpoint_path)\n",
    "\n",
    "print(f\"✓ Saved recommender to: {rec_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Test Full System\n\n**What we've trained so far (all SUPERVISED, no RL yet):**\n\n1. **RL Actor Network** (Stage 1):\n   - Trained with MSE loss on conversation pairs\n   - Predicts embeddings for next concepts to explore\n   - NOT using reinforcement learning yet (that's Stage 3)\n\n2. **Two-Tower Recommender**:\n   - Trained with BPR loss on user preferences\n   - Maps conversation → movie recommendations\n\n**NOT trained yet:**\n- RL Critic (value function) - only needed for Stage 3 RL\n- User simulator - exists but not used yet\n- Stage 3 end-to-end RL with rewards"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate a conversation with REAL user simulator\nprint(\"\\n\" + \"=\"*60)\nprint(\"QELM CONVERSATION DEMO (with User Simulator)\")\nprint(\"=\"*60)\n\n# Initialize user simulator with real MovieLens data\nfrom qelm.agents.user_simulator import MovieLensLLMSimulator\n\nuser_sim = MovieLensLLMSimulator(\n    movielens_data_path='data/ml-25m',\n    model_name='gpt-4o-mini',  # Use GPT-4o-mini for simulation\n    min_ratings=50\n)\n\n# Sample a user profile\nuser_profile = user_sim.sample_user()\nprint(f\"\\n👤 Simulated User Profile:\")\nprint(f\"   Liked: {', '.join(user_profile['liked_movies'][:3])}\")\nprint(f\"   Genres: {', '.join([g[0] for g in user_profile['preferred_genres']])}\")\n\n# User starts with an initial statement\ninitial_question = \"Hi! What kind of movies do you enjoy?\"\nresponse1 = user_sim.simulate_response(initial_question, user_profile)\nqelm.process_user_response(response1)\nprint(f\"\\n🤖 QELM: {initial_question}\")\nprint(f\"👤 User: {response1}\")\n\n# System asks first question based on user input\nquestion1 = qelm.select_next_question(explore=False, verbose=True)\nprint(f\"\\n🤖 QELM: {question1}\")\n\n# User responds with simulator\nresponse2 = user_sim.simulate_response(question1, user_profile)\nqelm.process_user_response(response2)\nprint(f\"👤 User: {response2}\")\n\n# System asks second question\nquestion2 = qelm.select_next_question(explore=False, verbose=True)\nprint(f\"\\n🤖 QELM: {question2}\")\n\n# User responds again\nresponse3 = user_sim.simulate_response(question2, user_profile)\nqelm.process_user_response(response3)\nprint(f\"👤 User: {response3}\")\n\n# Get final recommendations based on full conversation\nconv_state = qelm.encode_conversation_state()\nfinal_recs = rec_trainer.recommend(conv_state, top_k=10)\n\nprint(f\"\\n\\n📽️ FINAL RECOMMENDATIONS:\")\nfor i, (movie_id, title, score) in enumerate(final_recs, 1):\n    print(f\"{i}. {title}: {score:.3f}\")\n\n# Check if any user's liked movies are in recommendations\nuser_liked_titles = set(user_profile['liked_movies'])\nrecommended_titles = set([title for _, title, _ in final_recs])\nhits = user_liked_titles & recommended_titles\n\nif hits:\n    print(f\"\\n✅ SUCCESS: Recommended {len(hits)} movies user actually likes!\")\n    print(f\"   Hits: {', '.join(list(hits)[:3])}\")\nelse:\n    print(f\"\\n⚠️  No direct hits, but recommendations match user's genre preferences\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test full QELM system\nfrom qelm.models.embedding_qelm import EmbeddingQLEM\n\n# Note: This will use GPT for question generation (requires API key)\nqelm = EmbeddingQLEM(movielens_data_path=None)\n\n# Load trained RL weights\nqelm.rl_agent.actor.load_state_dict(\n    torch.load(checkpoint_path, weights_only=False)['actor_state_dict']\n)\n\nprint(\"✓ Loaded trained RL actor\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate a conversation\nprint(\"\\n\" + \"=\"*60)\nprint(\"QELM CONVERSATION DEMO\")\nprint(\"=\"*60)\n\n# User starts the conversation\nresponse1 = \"I love Christopher Nolan films, especially Inception and Interstellar\"\nqelm.process_user_response(response1)\nprint(f\"\\n👤 User: {response1}\")\n\n# System asks first question based on user input\nquestion1 = qelm.select_next_question(explore=False, verbose=True)\nprint(f\"\\n🤖 QELM: {question1}\")\n\n# User responds\nresponse2 = \"I also enjoy psychological thrillers with complex narratives\"\nqelm.process_user_response(response2)\nprint(f\"\\n👤 User: {response2}\")\n\n# System asks second question\nquestion2 = qelm.select_next_question(explore=False, verbose=True)\nprint(f\"\\n🤖 QELM: {question2}\")\n\n# Get recommendations based on full conversation\nconv_state = qelm.encode_conversation_state()\nfinal_recs = rec_trainer.recommend(conv_state, top_k=5)\n\nprint(f\"\\n\\n📽️ RECOMMENDATIONS:\")\nfor i, (movie_id, title, score) in enumerate(final_recs, 1):\n    print(f\"{i}. {title}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Checkpoints (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoints to local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Zip checkpoints\n",
    "!zip -r qelm_checkpoints.zip /content/drive/MyDrive/qelm_checkpoints/\n",
    "\n",
    "# Download\n",
    "files.download('qelm_checkpoints.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we trained:**\n",
    "1. ✅ Stage 1: RL actor to predict semantic embeddings\n",
    "2. ✅ Two-Tower Recommender: Dialogue state → Movie recommendations\n",
    "\n",
    "**Checkpoints saved to:**\n",
    "- `/content/drive/MyDrive/qelm_checkpoints/stage1_final.pt`\n",
    "- `/content/drive/MyDrive/qelm_checkpoints/recommender_final.pt`\n",
    "\n",
    "**Next steps:**\n",
    "- Train on real MovieLens data\n",
    "- Scrape more Reddit conversations\n",
    "- Train Stage 3 (end-to-end RL with reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}