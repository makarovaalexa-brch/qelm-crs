{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QELM Training on Google Colab\n",
    "\n",
    "This notebook trains the embedding-based QELM system on GPU.\n",
    "\n",
    "**What it does:**\n",
    "1. Clones the code from GitHub\n",
    "2. Installs dependencies\n",
    "3. Mounts Google Drive for checkpoints\n",
    "4. Trains Stage 1 (supervised pretraining)\n",
    "5. Trains the two-tower recommender\n",
    "6. Tests the full system\n",
    "\n",
    "**Prerequisites:**\n",
    "- Push your code to GitHub\n",
    "- Set OpenAI API key (for question generation)\n",
    "- Use GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Clone Code\n\n**For private repos**, you have 3 options:\n1. Make the repo public temporarily\n2. Use a Personal Access Token (see cell below for instructions)\n3. Upload code to Google Drive and copy from there\n\n**For public repos**, just run the clone command directly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository\n# Option 1: Public repo (easiest)\n!git clone https://github.com/makarovaalexa-brch/qelm-crs.git\n\n# Option 2: Private repo with personal access token\n# Create token at: https://github.com/settings/tokens (select 'repo' scope)\n# Then use: !git clone https://YOUR_TOKEN@github.com/makarovaalexa-brch/qelm-crs.git\n\n# Option 3: Upload files from Google Drive instead\n# Uncomment if you've already uploaded the code to Drive:\n# !cp -r /content/drive/MyDrive/qelm-crs /content/\n\n# Change to directory\n%cd qelm-crs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q openai\n",
    "!pip install -q pandas numpy scikit-learn tqdm\n",
    "!pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "!mkdir -p /content/drive/MyDrive/qelm_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Enter your OpenAI API key when prompted\n",
    "api_key = getpass('Enter OpenAI API Key: ')\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create sample Reddit data (or scrape real data)\n%cd /content/qelm-crs\n\n# Option 1: Use 5 sample posts (fast, for testing pipeline)\n!python src/qelm/data/reddit_scraper.py --sample --output-dir data/reddit\n\n# Option 2: Scrape real Reddit data (100 posts per subreddit, ~500 total)\n# Uncomment for actual training:\n# !python src/qelm/data/reddit_scraper.py --max-posts 100 --output-dir data/reddit"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data\n",
    "import json\n",
    "\n",
    "with open('data/reddit/sample_questions.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(f\"Loaded {len(data)} sample questions\")\n",
    "print(\"\\nExample:\")\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Stage 1 (Supervised Pretraining)\n",
    "\n",
    "This teaches the RL actor to predict embeddings in the right semantic space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import sys\n",
    "sys.path.append('/content/qelm-crs/src')\n",
    "\n",
    "from qelm.models.embedding_qelm import SentenceBERTEmbeddingSpace, EmbeddingActorCritic\n",
    "from qelm.training.stage1_supervised import Stage1Trainer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "print(\"Initializing SentenceBERT embedding space...\")\n",
    "embedding_space = SentenceBERTEmbeddingSpace(movielens_data_path=None)\n",
    "\n",
    "print(\"\\nInitializing RL actor...\")\n",
    "rl_agent = EmbeddingActorCritic(\n",
    "    state_dim=384,  # SentenceBERT\n",
    "    embedding_dim=384  # SentenceBERT\n",
    ")\n",
    "\n",
    "print(\"\\nInitializing encoder...\")\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"\\n‚úì Initialization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create trainer\ntrainer = Stage1Trainer(\n    rl_agent=rl_agent,\n    embedding_space=embedding_space,\n    reddit_data_path='data/reddit',\n    encoder=encoder\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Stage 1\n",
    "trainer.train(\n",
    "    epochs=20,  # More epochs on GPU\n",
    "    batch_size=64,  # Larger batch on GPU\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Stage 1\n",
    "trainer.evaluate(num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint to Google Drive\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path('/content/drive/MyDrive/qelm_checkpoints')\n",
    "checkpoint_path = checkpoint_dir / 'stage1_final.pt'\n",
    "\n",
    "torch.save({\n",
    "    'actor_state_dict': rl_agent.actor.state_dict(),\n",
    "    'train_losses': trainer.train_losses,\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"‚úì Saved checkpoint to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Two-Tower Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import recommender\n",
    "from qelm.models.two_tower_recommender import (\n",
    "    TwoTowerRecommender,\n",
    "    MovieCatalog,\n",
    "    RecommenderTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize recommender\n",
    "movie_catalog = MovieCatalog(movielens_data_path=None)  # Use sample data\n",
    "\n",
    "recommender = TwoTowerRecommender(\n",
    "    state_dim=384,\n",
    "    embedding_dim=128\n",
    ")\n",
    "\n",
    "rec_trainer = RecommenderTrainer(recommender, movie_catalog, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data\n",
    "sample_conversations = [\n",
    "    \"I love action movies with great cinematography like The Dark Knight\",\n",
    "    \"I enjoy mind-bending sci-fi films like Inception and Interstellar\",\n",
    "    \"I prefer dark crime dramas with great dialogue like Pulp Fiction\",\n",
    "    \"I like sci-fi movies with philosophical themes like The Matrix\",\n",
    "    \"I want intense space exploration films like Interstellar\",\n",
    "] * 10  # Repeat for more training data\n",
    "\n",
    "sample_liked_movies = [\n",
    "    [1],  # The Dark Knight\n",
    "    [2, 5],  # Inception, Interstellar\n",
    "    [3],  # Pulp Fiction\n",
    "    [4],  # The Matrix\n",
    "    [5],  # Interstellar\n",
    "] * 10\n",
    "\n",
    "print(f\"Training on {len(sample_conversations)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train recommender\n",
    "rec_trainer.train(\n",
    "    conversations=sample_conversations,\n",
    "    liked_movies=sample_liked_movies,\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save recommender checkpoint\n",
    "rec_checkpoint_path = checkpoint_dir / 'recommender_final.pt'\n",
    "\n",
    "torch.save({\n",
    "    'user_tower': recommender.user_tower.state_dict(),\n",
    "    'item_tower': recommender.item_tower.state_dict(),\n",
    "}, rec_checkpoint_path)\n",
    "\n",
    "print(f\"‚úì Saved recommender to: {rec_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Full System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test recommender\n",
    "test_conversation = \"I want something like Inception with mind-bending sci-fi elements\"\n",
    "test_state = encoder.encode(test_conversation, convert_to_numpy=True)\n",
    "\n",
    "recommendations = rec_trainer.recommend(test_state, top_k=5)\n",
    "\n",
    "print(f\"\\nQuery: {test_conversation}\\n\")\n",
    "print(\"Recommendations:\")\n",
    "for i, (movie_id, title, score) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {title}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full QELM system\n",
    "from qelm.models.embedding_qelm import EmbeddingQLEM\n",
    "\n",
    "# Note: This will use GPT for question generation (requires API key)\n",
    "qelm = EmbeddingQLEM(movielens_data_path=None)\n",
    "\n",
    "# Load trained RL weights\n",
    "qelm.rl_agent.actor.load_state_dict(\n",
    "    torch.load(checkpoint_path)['actor_state_dict']\n",
    ")\n",
    "\n",
    "print(\"‚úì Loaded trained RL actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a conversation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QELM CONVERSATION DEMO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# First question\n",
    "question1 = qelm.select_next_question(explore=False, verbose=True)\n",
    "print(f\"\\nü§ñ QELM: {question1}\")\n",
    "\n",
    "# Simulate response\n",
    "response1 = \"I love Christopher Nolan films, especially Inception and Interstellar\"\n",
    "qelm.process_user_response(response1)\n",
    "print(f\"\\nüë§ User: {response1}\")\n",
    "\n",
    "# Second question\n",
    "question2 = qelm.select_next_question(explore=False, verbose=True)\n",
    "print(f\"\\nü§ñ QELM: {question2}\")\n",
    "\n",
    "# Get recommendations based on conversation\n",
    "conv_state = qelm.encode_conversation_state()\n",
    "final_recs = rec_trainer.recommend(conv_state, top_k=5)\n",
    "\n",
    "print(f\"\\n\\nüìΩÔ∏è RECOMMENDATIONS:\")\n",
    "for i, (movie_id, title, score) in enumerate(final_recs, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Checkpoints (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoints to local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Zip checkpoints\n",
    "!zip -r qelm_checkpoints.zip /content/drive/MyDrive/qelm_checkpoints/\n",
    "\n",
    "# Download\n",
    "files.download('qelm_checkpoints.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we trained:**\n",
    "1. ‚úÖ Stage 1: RL actor to predict semantic embeddings\n",
    "2. ‚úÖ Two-Tower Recommender: Dialogue state ‚Üí Movie recommendations\n",
    "\n",
    "**Checkpoints saved to:**\n",
    "- `/content/drive/MyDrive/qelm_checkpoints/stage1_final.pt`\n",
    "- `/content/drive/MyDrive/qelm_checkpoints/recommender_final.pt`\n",
    "\n",
    "**Next steps:**\n",
    "- Train on real MovieLens data\n",
    "- Scrape more Reddit conversations\n",
    "- Train Stage 3 (end-to-end RL with reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}